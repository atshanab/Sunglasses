<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover" />
  <title>QR → Camera → Sunglasses Filter</title>
  <style>
    html, body {
      margin: 0;
      padding: 0;
      height: 100%;
      background: #000;
      color: #fff;
      font-family: system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif;
    }
    .app {
      position: fixed;
      inset: 0;
      display: grid;
      grid-template-rows: auto 1fr auto;
    }
    header, footer {
      padding: 8px 12px;
      background: rgba(0,0,0,0.5);
      backdrop-filter: blur(6px);
    }
    header { display:flex; align-items:center; gap: 8px; }
    header h1 { font-size: 16px; margin:0; font-weight:600; letter-spacing:0.3px;}
    #stage {
      position: relative;
      overflow: hidden;
      background: #000;
    }
    #video {
      position: absolute;
      inset: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
      transform: scaleX(-1); /* mirror for front camera UX */
    }
    #canvas {
      position: absolute;
      inset: 0;
      width: 100%;
      height: 100%;
      pointer-events: none;
    }
    .controls {
      display: flex;
      gap: 8px;
      align-items: center;
      justify-content: center;
      flex-wrap: wrap;
    }
    button, select {
      -webkit-appearance: none;
      appearance: none;
      padding: 10px 14px;
      border-radius: 999px;
      border: 0;
      font-weight: 600;
      background: #fff;
      color: #111;
      box-shadow: 0 4px 16px rgba(0,0,0,0.25);
      cursor: pointer;
    }
    button:disabled { opacity: 0.6; cursor: not-allowed; }
    .badge {
      font-size: 12px;
      opacity: 0.8;
    }
    .hidden { display: none !important; }
    .toast {
      position: absolute;
      top: 12px;
      left: 50%;
      transform: translateX(-50%);
      background: rgba(0,0,0,0.6);
      padding: 8px 12px;
      border-radius: 999px;
      font-size: 12px;
      display: none;
    }
    .toast.show { display: inline-block; }
  </style>
</head>
<body>
  <div class="app">
    <header>
      <h1>AR Sunglasses</h1>
      <div class="badge" id="status">loading…</div>
    </header>

    <div id="stage">
      <video id="video" playsinline autoplay muted></video>
      <canvas id="canvas"></canvas>
      <div class="toast" id="toast"></div>
    </div>

    <footer>
      <div class="controls">
        <button id="startBtn">Start Camera</button>
        <button id="flipBtn" class="hidden">Flip Camera</button>
        <select id="filterSelect" title="Filter">
          <option value="sunglasses">Sunglasses</option>
        </select>
        <span class="badge">If the camera doesn’t start, tap “Start Camera” and allow access.</span>
      </div>
    </footer>
  </div>

  <!-- MediaPipe Tasks Vision bundle (Face Landmarker) -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.10/vision_bundle_mediapipe.js"></script>

  <script>
  (function(){
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const startBtn = document.getElementById('startBtn');
    const flipBtn = document.getElementById('flipBtn');
    const filterSelect = document.getElementById('filterSelect');
    const statusEl = document.getElementById('status');
    const toast = document.getElementById('toast');

    let currentStream = null;
    let usingFront = true;
    let faceLandmarker = null;
    let running = false;
    let lastVideoTime = -1;

    // Build an inline SVG sunglasses asset (vector, scalable)
    const sunglassesImg = new Image();
    const svg = `
      <svg xmlns='http://www.w3.org/2000/svg' width='800' height='300' viewBox='0 0 800 300'>
        <defs>
          <linearGradient id='g' x1='0' y1='0' x2='1' y2='1'>
            <stop offset='0' stop-color='#111'/>
            <stop offset='1' stop-color='#333'/>
          </linearGradient>
          <filter id='shadow' x='-50%' y='-50%' width='200%' height='200%'>
            <feDropShadow dx='0' dy='6' stdDeviation='8' flood-color='rgba(0,0,0,0.6)'/>
          </filter>
        </defs>
        <g filter='url(#shadow)'>
          <!-- Bridge -->
          <rect x='380' y='110' width='40' height='20' rx='10' fill='url(#g)'/>
          <!-- Left frame -->
          <rect x='140' y='90' width='220' height='140' rx='24' fill='url(#g)' stroke='#000' stroke-width='6'/>
          <rect x='168' y='120' width='164' height='84' rx='16' fill='rgba(0,0,0,0.55)'/>
          <!-- Right frame -->
          <rect x='440' y='90' width='220' height='140' rx='24' fill='url(#g)' stroke='#000' stroke-width='6'/>
          <rect x='468' y='120' width='164' height='84' rx='16' fill='rgba(0,0,0,0.55)'/>
          <!-- Temples -->
          <rect x='40' y='130' width='120' height='22' rx='11' fill='url(#g)'/>
          <rect x='640' y='130' width='120' height='22' rx='11' fill='url(#g)'/>
        </g>
      </svg>`;
    sunglassesImg.src = 'data:image/svg+xml;utf8,' + encodeURIComponent(svg);

    function showToast(msg, ms=1500){
      toast.textContent = msg;
      toast.classList.add('show');
      clearTimeout(showToast._t);
      showToast._t = setTimeout(()=>toast.classList.remove('show'), ms);
    }

    function setStatus(text){ statusEl.textContent = text; }

    function fitCanvas(){
      canvas.width = video.videoWidth || canvas.clientWidth;
      canvas.height = video.videoHeight || canvas.clientHeight;
    }

    async function loadFaceLandmarker(){
      if (faceLandmarker) return;
      setStatus('loading face model…');
      const vision = window;
      const filesetResolver = await vision.FilesetResolver.forVisionTasks(
        'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.10/wasm'
      );
      faceLandmarker = await vision.FaceLandmarker.createFromOptions(filesetResolver, {
        baseOptions: {
          modelAssetPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.10/models/face_landmarker.task'
        },
        numFaces: 1,
        runningMode: 'VIDEO',
        outputFaceBlendshapes: false,
        outputFacialTransformationMatrixes: false
      });
      setStatus('model ready');
    }

    async function startCamera(front=true){
      stopCamera();
      usingFront = front;
      const constraints = {
        audio: false,
        video: {
          facingMode: front ? 'user' : 'environment',
          width: { ideal: 1280 },
          height: { ideal: 720 }
        }
      };
      try {
        const stream = await navigator.mediaDevices.getUserMedia(constraints);
        currentStream = stream;
        video.srcObject = stream;
        await video.play().catch(()=>{});
        fitCanvas();
        startBtn.classList.add('hidden');
        flipBtn.classList.remove('hidden');
        setStatus(front ? 'front camera' : 'rear camera');
        return true;
      } catch (err) {
        console.warn('getUserMedia error:', err);
        setStatus('tap Start and allow camera');
        startBtn.classList.remove('hidden');
        return false;
      }
    }

    function stopCamera(){
      if (currentStream){
        for (const t of currentStream.getTracks()) t.stop();
        currentStream = null;
      }
    }

    function drawSunglassesFromLandmarks(landmarks){
      if (!landmarks || landmarks.length === 0) return;
      const pts = landmarks[0]; // first (and only) face

      // Use outer eye corners for robust width and angle
      const LEFT_OUTER = 33;  // left eye outer corner
      const RIGHT_OUTER = 263; // right eye outer corner

      const l = pts[LEFT_OUTER];
      const r = pts[RIGHT_OUTER];

      // Landmarks are normalized [0..1] in image coordinates.
      const W = canvas.width;
      const H = canvas.height;
      const lx = (1 - l.x) * W; // mirrored because video is mirrored
      const ly = l.y * H;
      const rx = (1 - r.x) * W;
      const ry = r.y * H;

      const cx = (lx + rx) / 2;
      const cy = (ly + ry) / 2;

      const dx = rx - lx;
      const dy = ry - ly;
      const angle = Math.atan2(dy, dx);

      const eyeDist = Math.hypot(dx, dy);
      // Scale: glasses width ~ 2.5x eye distance (tweakable)
      const width = eyeDist * 2.5;
      const height = width * (300/800); // preserve SVG aspect ratio (800x300)

      ctx.save();
      // Because the video is already mirrored, our landmark x-coords are mirrored above.
      // Draw normally.
      ctx.translate(cx, cy);
      ctx.rotate(angle);
      ctx.globalAlpha = 1.0;
      ctx.drawImage(sunglassesImg, -width/2, -height*0.45, width, height);
      ctx.restore();
    }

    function renderLoop(){
      if (!running) return;
      if (video.readyState >= 2){
        if (video.videoWidth !== canvas.width || video.videoHeight !== canvas.height){
          fitCanvas();
        }
        ctx.clearRect(0,0,canvas.width,canvas.height);
      }
      window.requestAnimationFrame(renderLoop);
    }

    async function detectLoop(){
      if (!running) return;
      if (!faceLandmarker) return;
      if (video.readyState >= 2){
        const t = performance.now();
        if (t !== lastVideoTime){
          lastVideoTime = t;
          const res = faceLandmarker.detectForVideo(video, t);
          if (res && res.faceLandmarks){
            drawSunglassesFromLandmarks(res.faceLandmarks);
          }
        }
      }
      // Aim ~60fps draw; detect loop can be throttled for performance.
      setTimeout(detectLoop, 16);
    }

    async function init(autoStart=true){
      try {
        await loadFaceLandmarker();
        if (autoStart){
          // Try to start automatically. Some browsers (iOS Safari) may block until a tap.
          const ok = await startCamera(true);
          running = true;
          renderLoop();
          detectLoop();
          if (!ok){
            showToast('Tap Start to allow camera');
          }
        }
      } catch (e){
        console.error(e);
        setStatus('failed to initialize');
        showToast('Initialization error');
      }
    }

    startBtn.addEventListener('click', async () => {
      const ok = await startCamera(usingFront);
      if (ok && !running){
        running = true;
        renderLoop();
        detectLoop();
      }
    });

    flipBtn.addEventListener('click', async () => {
      await startCamera(!usingFront);
      showToast(usingFront ? 'Rear camera' : 'Front camera');
    });

    // Handle page visibility (pause camera when tab hidden)
    document.addEventListener('visibilitychange', () => {
      if (document.hidden){
        stopCamera();
      } else {
        startCamera(usingFront);
      }
    });

    // Kick off
    window.addEventListener('load', () => {
      // Attempt autostart; if blocked, Start button remains visible.
      init(true);
    });

    // Resize canvas when orientation changes
    window.addEventListener('resize', fitCanvas);
  })();
  </script>
</body>
</html>
